# 大语言模型食用指南

该食用指南整理大语言模型发展历程以及部分相关技术。主要从模型架构，模型部署与加速，模型微调与应用等内容构成。

## 1、大模型发展背景

[chpt1大语言发展背景](./chpt1大语言发展背景.md)

在本章节中，简单介绍大模型发展背景，通过整理部分大模型的资料，增加读者对大语言模型的背景了解。

## 2、大语言模型技术路线

[chpt2大语言模型技术路线](./chpt2大语言模型技术路线.md)

在本章节中，大模型技术发展过程中出现的几种不同架构：Encoder-only、Decoder-only以及Encoder-Decoder架构。

分析不同架构之间的优缺点，以及进一步分析现阶段模型主流架构为Decoder-only的原因。

## 3、大模型部与加速指南

[chpt3大模型部署与加速指南](./chpt3大模型部署与加速指南.md)

以datawhale开源项目为例，通过在autodl平台上的服务器，部署大模型，并使用llama.cpp与vLLM进行模型推理加速

## 4、大模型微调

[chpt4大语言模型微调](./chpt4大语言模型微调.md)
通过代码构筑模型Lora微调和微调后模型载入，并以datawhale开源的RAG项目进行RAG项目讲解

## 5、如何评价大模型应用
[chpt5如何评估大模型应用](/docs/chpt5如何评估大模型应用.md)

## 6、其他构建大模型想法与思路
